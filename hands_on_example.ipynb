{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riq-NLzOl0Rm"
   },
   "source": [
    "# Hands-on example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Using cached mlflow-1.24.0-py3-none-any.whl (16.5 MB)\n",
      "Collecting alembic\n",
      "  Using cached alembic-1.7.7-py3-none-any.whl (210 kB)\n",
      "Requirement already satisfied: entrypoints in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (0.3)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: requests>=2.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (2.25.1)\n",
      "Requirement already satisfied: Flask in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (1.1.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (5.4.1)\n",
      "Collecting sqlparse>=0.3.1\n",
      "  Using cached sqlparse-0.4.2-py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (1.6.2)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (20.9)\n",
      "Collecting waitress\n",
      "  Using cached waitress-2.1.0-py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: click>=7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (7.1.2)\n",
      "Collecting docker>=4.0.0\n",
      "  Using cached docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (1.20.1)\n",
      "Collecting prometheus-flask-exporter\n",
      "  Using cached prometheus_flask_exporter-0.19.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: sqlalchemy in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (1.4.7)\n",
      "Collecting gitpython>=2.1.0\n",
      "  Using cached GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "Collecting protobuf>=3.7.0\n",
      "  Using cached protobuf-3.19.4-cp38-cp38-win_amd64.whl (895 kB)\n",
      "Requirement already satisfied: pytz in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (2021.1)\n",
      "Collecting databricks-cli>=0.8.7\n",
      "  Using cached databricks_cli-0.16.4-py3-none-any.whl\n",
      "Collecting querystring-parser\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: cloudpickle in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (1.6.0)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,>=3.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (3.10.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from databricks-cli>=0.8.7->mlflow) (1.15.0)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Using cached tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Using cached websocket_client-1.3.1-py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: pywin32==227 in c:\\programdata\\anaconda3\\lib\\site-packages (from docker>=4.0.0->mlflow) (227)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow) (3.4.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.17.3->mlflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.17.3->mlflow) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.17.3->mlflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.17.3->mlflow) (1.26.4)\n",
      "Collecting importlib-resources\n",
      "  Using cached importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.2.0-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy->mlflow) (1.0.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask->mlflow) (2.11.3)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask->mlflow) (1.0.1)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask->mlflow) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->Flask->mlflow) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->mlflow) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->mlflow) (2.8.1)\n",
      "Requirement already satisfied: prometheus-client in c:\\programdata\\anaconda3\\lib\\site-packages (from prometheus-flask-exporter->mlflow) (0.10.1)\n",
      "Installing collected packages: smmap, websocket-client, tabulate, Mako, importlib-resources, gitdb, waitress, sqlparse, querystring-parser, protobuf, prometheus-flask-exporter, gitpython, docker, databricks-cli, alembic, mlflow\n",
      "Successfully installed Mako-1.2.0 alembic-1.7.7 databricks-cli-0.16.4 docker-5.0.3 gitdb-4.0.9 gitpython-3.1.27 importlib-resources-5.4.0 mlflow-1.24.0 prometheus-flask-exporter-0.19.0 protobuf-3.19.4 querystring-parser-1.2.4 smmap-5.0.0 sqlparse-0.4.2 tabulate-0.8.9 waitress-2.1.0 websocket-client-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow, version 1.24.0\n"
     ]
    }
   ],
   "source": [
    "!mlflow --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "n4t2auXBl0Ro"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iirPimY1l0Rq"
   },
   "source": [
    "## 0. The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IB20sygfl0Rq"
   },
   "source": [
    "* The data set used in this example is from http://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "* P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "* Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJPAKh-kl0Rr"
   },
   "source": [
    "## 1. Tracking experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/wine-quality.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-l2Oa0al0Rr"
   },
   "source": [
    "### Tracking stores\n",
    "MLflow supports two types of backend stores: *file store* and *database-backed* store.\n",
    "\n",
    "- Local file path (specified as file:/my/local/dir), where data is just directly stored locally. Defaults to `mlruns/`\n",
    "- Database encoded as <dialect>+<driver>://<username>:<password>@<host>:<port>/<database>. Mlflow supports the dialects mysql, mssql, sqlite, and postgresql. For more details, see SQLAlchemy database uri.\n",
    "- HTTP server (specified as https://my-server:5000), which is a server hosting an MLFlow tracking server.\n",
    "- Databricks workspace (specified as databricks or as databricks://<profileName>, a Databricks CLI profile.\n",
    "    \n",
    "### Artifact stores\n",
    "- Amazon S3\n",
    "- Azure Blob Storage\n",
    "- Google Cloud Storage\n",
    "- FTP server\n",
    "- SFTP Server\n",
    "- NFS\n",
    "- HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4aPuSZBl0Rs"
   },
   "source": [
    "Start the MLflow tracking server by \n",
    "\n",
    "```\n",
    "mlflow server \\\n",
    "    --backend-store-uri /mnt/persistent-disk \\\n",
    "    --default-artifact-root s3://my-mlflow-bucket/ \\\n",
    "    --host 0.0.0.0\n",
    "    --port 5000\n",
    "```\n",
    "\n",
    "or use the default storage method to write to `mlruns/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BokqsDwNl0Rs"
   },
   "outputs": [],
   "source": [
    "# mlflow server --backend-store-uri mlruns/ --default-artifact-root mlruns/ --host 0.0.0.0 --port 5000\n",
    "remote_server_uri = \"http://127.0.0.1:5000\" # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)  # or set the MLFLOW_TRACKING_URI in the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NDB3Plu0l0Rt",
    "outputId": "31cb6c71-cc7a-4eba-b05c-632c4e6eed92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://127.0.0.1:5000'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3pTG8gll0Rt",
    "outputId": "50159827-8812-42f1-a10a-a7d469ffb8d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'ElasticNet_wine' does not exist. Creating a new experiment\n"
     ]
    }
   ],
   "source": [
    "exp_name = \"ElasticNet_wine\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZAFLOtIl0Rt"
   },
   "source": [
    "### What do we track?\n",
    "\n",
    "- **Code Version**: Git commit hash used for the run (if it was run from an MLflow Project)\n",
    "- **Start & End Time**: Start and end time of the run\n",
    "- **Source**: what code run?\n",
    "- **Parameters**: Key-value input parameters.\n",
    "- **Metrics**: Key-value metrics, where the value is numeric (can be updated over the run)\n",
    "- **Artifacts**: Output files in any format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSsMTrZal0Ru"
   },
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    # compute relevant metrics\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "    train, test = train_test_split(data)\n",
    "\n",
    "    # The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "    train_x = train.drop([\"quality\"], axis=1)\n",
    "    test_x = test.drop([\"quality\"], axis=1)\n",
    "    train_y = train[[\"quality\"]]\n",
    "    test_y = test[[\"quality\"]]\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "def train(alpha=0.5, l1_ratio=0.5):\n",
    "    # train a model with given parameters\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "\n",
    "    # Read the wine-quality csv file (make sure you're running this from the root of MLflow!)\n",
    "    data_path = \"data/wine-quality.csv\"\n",
    "    train_x, train_y, test_x, test_y = load_data(data_path)\n",
    "\n",
    "    # Useful for multiple runs (only doing one run in this sample notebook)    \n",
    "    with mlflow.start_run():\n",
    "        # Execute ElasticNet\n",
    "        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "        lr.fit(train_x, train_y)\n",
    "\n",
    "        # Evaluate Metrics\n",
    "        predicted_qualities = lr.predict(test_x)\n",
    "        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "        # Print out metrics\n",
    "        print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        # Log parameter, metrics, and model to MLflow\n",
    "        mlflow.log_param(key=\"alpha\", value=alpha)\n",
    "        mlflow.log_param(key=\"l1_ratio\", value=l1_ratio)\n",
    "        mlflow.log_metric(key=\"rmse\", value=rmse)\n",
    "        mlflow.log_metrics({\"mae\": mae, \"r2\": r2})\n",
    "        mlflow.log_artifact(data_path)\n",
    "        print(\"Save to: {}\".format(mlflow.get_artifact_uri()))\n",
    "        \n",
    "        mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6Pd_Z2ol0Ru"
   },
   "outputs": [],
   "source": [
    "# could also do\n",
    "# with mlflow.start_run():\n",
    "#     for epoch in range(0, 3):\n",
    "#          mlflow.log_metric(key=\"quality\", value=2*epoch, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfZM5dwCl0Rv",
    "outputId": "67736d94-a1e4-4a5f-8f24-a404dec8f769"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.500000, l1_ratio=0.500000):\n",
      "  RMSE: 0.82224284975954\n",
      "  MAE: 0.6278761410160693\n",
      "  R2: 0.12678721972772689\n",
      "Save to: mlruns/1/a991b24c4ef34793bf1938d2ad70fbf8/artifacts\n"
     ]
    }
   ],
   "source": [
    "train(0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzgTHqeUl0Rv",
    "outputId": "4ac68fd6-3dd6-40ab-891a-65aeedf71e71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.200000, l1_ratio=0.200000):\n",
      "  RMSE: 0.7859129997062342\n",
      "  MAE: 0.6155290394093895\n",
      "  R2: 0.2022463182289208\n",
      "Save to: mlruns/1/cf2308f69cd14a578c4f8f0f6f09a1d5/artifacts\n"
     ]
    }
   ],
   "source": [
    "train(0.2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqJM762Ul0Rv",
    "outputId": "7f1cc0b9-73e9-4537-f605-3e6127ffe716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.100000, l1_ratio=0.100000):\n",
      "  RMSE: 0.7792546522251949\n",
      "  MAE: 0.6112547988118586\n",
      "  R2: 0.2157063843066196\n",
      "Save to: mlruns/1/3627a8dd69d14bee919205e5e69c8bca/artifacts\n"
     ]
    }
   ],
   "source": [
    "train(0.1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6v3pYK4l0Rw"
   },
   "source": [
    "### 1.1 Comparing runs\n",
    "Run `mlflow ui` in a terminal or `http://your-tracking-server-host:5000` to view the experiment log and visualize and compare different runs and experiments. The logs and the model artifacts are saved in the `mlruns` directory (or where you specified)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nAeaLfIl0Rw"
   },
   "source": [
    "## 2. Packaging the experiment as a MLflow project as conda env\n",
    "\n",
    "Specify the entrypoint for this project by creating a `MLproject` file and adding an conda environment with a `conda.yaml`. You can copy the yaml file from the experiment logs.\n",
    "\n",
    "To run this project, invoke `mlflow run . -P alpha=0.42`. After running this command, MLflow runs your training code in a new Conda environment with the dependencies specified in `conda.yaml`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNXFJm-Ql0Rw"
   },
   "source": [
    "## 3. Deploy the model\n",
    "\n",
    "Deploy the model locally by running \n",
    "\n",
    "`mlflow models serve -m mlruns/0/f5f7c052ddc5469a852aa52c14cabdf1/artifacts/model/ -h 0.0.0.0 -p 1234`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1H7Dg7M9l0Rw"
   },
   "source": [
    "Test the endpoint:\n",
    "\n",
    "`curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data '{\"columns\":[\"alcohol\", \"chlorides\", \"citric acid\", \"density\", \"fixed acidity\", \"free sulfur dioxide\", \"pH\", \"residual sugar\", \"sulphates\", \"total sulfur dioxide\", \"volatile acidity\"],\"data\":[[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}' http://0.0.0.0:1234/invocations`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TB4LYGyvl0Rw"
   },
   "source": [
    "You can also simply build a docker image from your model\n",
    "\n",
    "`mlflow models build-docker -m mlruns/1/d671f37a9c7f478989e67eb4ff4d1dac/artifacts/model/ -n elastic_net_wine`\n",
    "\n",
    "and run the container with\n",
    "\n",
    "`docker run -p 8080:8080 elastic_net_wine`.\n",
    "\n",
    "Or you can directly deploy to AWS sagemaker or Microsoft Azure ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-Qdi8Ggl0Rx"
   },
   "source": [
    "## 4. Tagging runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6AfgjUel0Rx",
    "outputId": "3e96403f-738f-4b47-bd6c-c9aac1d7e33f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='mlruns/1', experiment_id='1', lifecycle_stage='active', name='ElasticNet_wine', tags={}>, <Experiment: artifact_location='mlruns/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiments = client.list_experiments() # returns a list of mlflow.entities.Experiment\n",
    "print(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTt5CkDvl0Rx",
    "outputId": "b4dacd16-d665-43d0-b462-08dc39b429cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Run: data=<RunData: metrics={'mae': 0.6112547988118586,\n",
      " 'r2': 0.2157063843066196,\n",
      " 'rmse': 0.7792546522251949}, params={'alpha': '0.1', 'l1_ratio': '0.1'}, tags={'mlflow.source.name': '/home/tobias/.local/share/virtualenvs/pydataberlin-2019-97Azk3Vx/lib/python3.6/site-packages/ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'tobias'}>, info=<RunInfo: artifact_uri='mlruns/1/3627a8dd69d14bee919205e5e69c8bca/artifacts', end_time=1570544741270, experiment_id='1', lifecycle_stage='active', run_id='3627a8dd69d14bee919205e5e69c8bca', run_uuid='3627a8dd69d14bee919205e5e69c8bca', start_time=1570544740678, status='FINISHED', user_id='tobias'>>\n"
     ]
    }
   ],
   "source": [
    "# get the run\n",
    "_run = client.get_run(run_id=\"3627a8dd69d14bee919205e5e69c8bca\")\n",
    "print(_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yaOnrNOl0Rx"
   },
   "outputs": [],
   "source": [
    "# add a tag to the run\n",
    "dt = datetime.now().strftime(\"%d-%m-%Y (%H:%M:%S.%f)\")\n",
    "client.set_tag(_run.info.run_id, \"deployed\", dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0TrwHaAl0Ry"
   },
   "source": [
    "# Connect to a postgesql db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APTaW9xTl0Ry"
   },
   "source": [
    "Connect to the db:\n",
    "    \n",
    "`sudo -u postgres psql`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHE9oiK_l0Ry"
   },
   "source": [
    "Create a user and a database for the tracking server:\n",
    "    \n",
    "```\n",
    "CREATE DATABASE mlflow;\n",
    "CREATE USER mlflow WITH ENCRYPTED PASSWORD 'mlflow';\n",
    "GRANT ALL PRIVILEGES ON DATABASE mlflow TO mlflow;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hteo0R-Tl0Ry"
   },
   "source": [
    "```\n",
    "mlflow server --backend-store-uri postgresql://mlflow:mlflow@localhost/mlflow --default-artifact-root file:/home/tobias/Projects/mlflow_talk/pydataberlin-2019/mlruns/ -h 0.0.0.0 -p 8000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAuCBPBll0Ry"
   },
   "source": [
    "Run the notebook again with this tracking server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9ZiDWopl0Ry"
   },
   "source": [
    "Look at the db:\n",
    "\n",
    "`psql mlflow`\n",
    "\n",
    "`SELECT * FROM experiments;`\n",
    "\n",
    "`SELECT * FROM runs;`"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hands_on_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
